
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Improving Object Detection via Local-global Contrastive Learning</title>

<!--   <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  <script type="text/javascript">
    window.MathJax = {
      tex: {
        MAXBUFFER: 10240, // Increase buffer size
        macros: {
          La: "\\mathcal{L}",
          Lb: "\\pazocal{L}"
        }
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script type="text/javascript">
    MathJax = {
      tex: {
        MAXBUFFER: 10240, // Increase buffer size
        macros: {
          La: "\\mathcal{L}",
          Lb: "\\pazocal{L}"
        }
      }
    };
  </script>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JRNK53Y20W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-JRNK53Y20W');
</script>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Improving Object Detection via Local-global Contrastive Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=luvIJkoAAAAJ&hl=en">Danai Triantafyllidou</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://parisots.github.io/">Sarah Parisot</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.bham.ac.uk/~leonarda/">Ales Leonardis</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://smcdonagh.github.io/">Steven McDonagh</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> Huawei Noah's Ark Lab,</span>
            <span class="author-block"><sup>2</sup> University of Edinburgh,</span>
            <span class="author-block"><sup>3</sup> University of Birmingham</span>
          </div>
            <div class="is-size-4 publication-authors">
            <span class="author-block", style="color:#346dc2">BMVC 2024</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="Improving_Object_Detection_via_Local_Global_Contrastive_Learning_BMVC_2024.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
                <span class="link-block">
                <a href="supplementary_Improving_Object_Detection_via_Local_Global_Contrastive_Learning_BMVC_2024-compressed.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.05058"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>ArXiv</span>
                </a>
              </span>
                <span class="link-block">
                <a href="Improving_Object_Detection_BMVC24_Poster.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-clone"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/danaitri"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Visual domain gaps often impact object detection performance. Image-to-image
          translation can mitigate this effect, where contrastive approaches enable learning of the
          image-to-image mapping under unsupervised regimes. However, existing methods often
          fail to handle content-rich scenes with multiple object instances, which manifests in
          unsatisfactory detection performance. Sensitivity to such instance-level content is typically
          only gained through object annotations, which can be expensive to obtain. Towards
          addressing this issue, we present a novel image-to-image translation method that specifically
          itargets cross-domain object detection. We formulate our approach as a contrastive
          learning framework with an inductive prior that optimises the appearance of object instances
          through spatial attention masks, implicitly delineating the scene into foreground
          regions associated with the target object instances and background non-object regions.
          Instead of relying on object annotations to explicitly account for object instances during
          translation, our approach learns to represent objects by contrasting local-global information.
          This affords investigation of an under-explored challenge: obtaining performant
          detection, under domain shifts, without relying on object annotations nor detector model
          fine-tuning. We experiment with multiple cross-domain object detection settings across
          three challenging benchmarks and report state-of-the-art performance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
        <div class="hero-body">
            <div class="container ">
                <h2 class="title is-3">Method </h2>
                <h2 class="title is-5">Model architecture</h2>

                <p>We introduce an inductive prior that optimises object instance appearance through spatial attention masks, effectively disentangling scenes into background and foreground regions. We adopt an encoder-decoder model where the encoder \(E_B\) acts as a feature extractor, generating an image representation of lower dimensionality.
                    We decompose our decoder into two components: a content generator \(G_C\), producing a set of \(n\) content maps \( \{C_t \mid t \in [0, n-1]\} \), and an attention generator \(G_A\) producing a set of \(n+1\) attention maps \( \{A_t \mid t \in [0, n]\} \). The translated image \(G(\mathbf{x})\) is recovered as: </p>

                <p>
                    \[
                    \begin{equation}
                    G(\mathbf{x})=\sum_{t=1}^{n} \underbrace{(C^{t} \odot A^{t})}_\textrm{foreground }
                    +
                    \underbrace{(x \odot A^{n+1})}_\textrm{background}.
                    \label{eq:fb}
                    \end{equation}
                    \]
                </p>
                <p style="margin-bottom:1cm;">
                </p>
                <div style="display: flex; justify-content: center;">
                    <img id="method_sliding" src="images/overview_camera_ready_2.jpg" width="800">
                </div>


                <h2 class="title is-5">Optimization</h2>
                <div style="display: flex; justify-content: center;">
                    <img id="equations" src="images/equations.png" width="400">
                </div>
                <p></p>

                &nbsp
                <ul style="list-style-type:circle;">
                  <li> \( \La_{adv} \)  adversarial term   </li>
                   <li> \( \La^{NCE} \) infoNCE loss on input and translated patches  </li>
                </ul>
                <p style="margin-bottom:1cm;">
                <h2 class="title is-5">Local-global contrastive learning</h2>
                <p>Our approach learns to represent objects by contrasting local-global information. We introduce multi-level supervision, directly on \(G_A\) features:</p>
                <p style="margin-bottom:1cm;">
                <div style="display: flex; justify-content: center;">
                    <img id="equations" src="images/local-global.png" width="400">
                </div>
                </p>
                </p>
                <p style="margin-bottom:1cm;">
                <ul style="list-style-type:circle;">
                  <li> \( g \rightarrow g \) loss term between \(  \mathit{global}  \) representations of \(\mathbf{x}\) </li>
                   <li>\( l \rightarrow l \) , \( l \rightarrow g \)  terms considering \(  \mathit{local}-\mathit{local}  \)  and \(  \mathit{local}-\mathit{global}  \) representations of \(\mathbf{x}\)   </li>
                   <li> for network layers \( L \); layer contribution weights \( w_{i} \)</li>
                </ul>
                </p>
                <p></p>
            </div>

        </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
        <h3 class="title is-3">Attention Maps</h3>
            <div id="results-carousel_COCO" class="carousel results-carousel">
                <div class="card">
                    <div class="card-image">
                        <img src="images/Slide1.jpg" alt="s1" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/Slide2.jpg" alt="s2" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/Slide3.jpg" alt="s3" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/Slide4.jpg" alt="s4" />
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->


<section class="hero is-small">
        <div class="hero-body">
            <div class="container ">
                <h2 class="title is-3">Experimental results </h2>
                <p style="margin-bottom:1cm;">
                <div style="display: flex; justify-content: center;">
                    <img id="method_sliding" src="images/table_foggy.png" width="800">
                </div>
                </p>
                <p style="margin-bottom:1cm;">
                <div style="display: flex; justify-content: center;">
                    <img id="method_sliding" src="images/table_sim_kitti.png" width="800">
                </div>
                </p>
            </div>
        </div>
</section>


<section class="hero is-small">
        <div class="hero-body">
            <div class="container ">
                <h2 class="title is-3">Ablative studies </h2>
                <p style="margin-bottom:1cm;">
                <div style="display: flex; justify-content: center;">
                    <img id="method_sliding" src="images/ablation1.png" width="800">
                </div>
                </p>
                <p style="margin-bottom:1cm;">
                <div style="display: flex; justify-content: center;">
                    <img id="method_sliding" src="images/ablation2.png" width="800">
                </div>
                </p>
                </p>
                <p style="margin-bottom:1cm;">
                <div style="display: flex; justify-content: center;">
                    <img id="method_sliding" src="images/tsne.png" width="800">
                </div>
                </p>
            </div>
        </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h5 class="title is-3"> Synthetic-to-real adaptation</h5>

        <h5 class="title is-5"><a href="https://fcav.engin.umich.edu/projects/driving-in-the-matrix">Sim10k</a> → <a href="https://www.cityscapes-dataset.com/">Cityscapes</a></a></h5>
            <div id="results-carousel_COCO" class="carousel results-carousel">
                <div class="card">
                    <div class="card-image">
                        <img src="images/s1.jpg" alt="s1" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/s2.jpg" alt="s2" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/s3.jpg" alt="s3" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/s4.jpg" alt="s4" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/s5.jpg" alt="s4" />
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->

<!-- Image carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h3 class="title is-3"> Cross-camera adaptation</h3>
            <h5 class="title is-5"><a href="https://www.cvlibs.net/datasets/kitti/">KITTI</a> → <a href="https://www.cityscapes-dataset.com/">Cityscapes</a></a></h5>
            <div id="results-carousel_COCO" class="carousel results-carousel">
                <div class="card">
                    <div class="card-image">
                        <img src="images/k1.jpg" alt="s1" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/k2.jpg" alt="s2" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/k3.jpg" alt="s3" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/k4.jpg" alt="s4" />
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->

<!-- Image carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h3 class="title is-3"> Adverse weather adaptation</h3>
            <h5 class="title is-5"><a href="https://paperswithcode.com/dataset/foggy-cityscapes">Foggy Cityscapes</a> → <a href="https://www.cityscapes-dataset.com/">Cityscapes</a></a></h5>
            <div id="results-carousel_COCO" class="carousel results-carousel">
                <div class="card">
                    <div class="card-image">
                        <img src="images/f1.jpg" alt="s1" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/f2.jpg" alt="s2" />
                    </div>
                </div>
                <div class="card">
                    <div class="card-image">
                        <img src="images/f3.jpg" alt="s3" />
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Danai Triantafyllidou, Sarah Parisot, Ales Leonardis, Steven McDonagh},
  title     = {Improving Object Detection via Local-global Contrastive Learning},
  journal   = {BMVC},
  year      = {2024},
}</code></pre>
  </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
    <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/js/bulma-carousel.min.js"></script>
    <script>
        bulmaCarousel.attach('#results-carousel_COCO', {
            slidesToScroll: 1,
            slidesToShow: 2,
            infinite: true,
            autoplay: false,
        });
    </script>

</body>
</html>
